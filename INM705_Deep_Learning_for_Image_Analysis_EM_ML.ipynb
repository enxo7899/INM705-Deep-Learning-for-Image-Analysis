{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/milan/INM705-Deep-Learning-for-Image-Analysis/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/home/milan/INM705-Deep-Learning-for-Image-Analysis/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Training WasteClassifier...\n",
            "Epoch 1: Train Loss: 3.0132, Train Acc: 23.13%, Val Loss: 1.5606, Val Acc: 27.18%\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Parent directory checkpoints does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[71], line 322\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Train both models separately\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining WasteClassifier...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 322\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Custom ResNet Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    325\u001b[0m train\u001b[38;5;241m.\u001b[39mtrain_model(model2, optimizer2, criterion2, train_loader, val_loader)\n",
            "File \u001b[0;32m~/INM705-Deep-Learning-for-Image-Analysis/train.py:55\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "File \u001b[0;32m~/INM705-Deep-Learning-for-Image-Analysis/venv/lib/python3.11/site-packages/torch/serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[0;32m~/INM705-Deep-Learning-for-Image-Analysis/venv/lib/python3.11/site-packages/torch/serialization.py:501\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/INM705-Deep-Learning-for-Image-Analysis/venv/lib/python3.11/site-packages/torch/serialization.py:472\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory checkpoints does not exist."
          ]
        }
      ],
      "source": [
        "# Necessary imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import detection\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "import train\n",
        "\n",
        "# Check for device: use MPS if available, otherwise use CPU\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = './dataset1'\n",
        "\n",
        "# Collect data helper functions\n",
        "def is_valid_file(file_path):\n",
        "    valid_extensions = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp']\n",
        "    return any(file_path.endswith(ext) for ext in valid_extensions)\n",
        "\n",
        "def collect_data(directory):\n",
        "    data = []\n",
        "    labels = []\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(os.listdir(directory)) if os.path.isdir(os.path.join(directory, cls))}\n",
        "    for cls, idx in class_to_idx.items():\n",
        "        class_path = os.path.join(directory, cls)\n",
        "        for file_path in glob.glob(os.path.join(class_path, '*')):\n",
        "            if is_valid_file(file_path):\n",
        "                data.append(file_path)\n",
        "                labels.append(idx)\n",
        "    return data, labels, class_to_idx\n",
        "\n",
        "# Data transformations and dataset preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), \n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Load and split dataset\n",
        "data, labels, class_to_idx = collect_data(dataset_path)\n",
        "dataset = CustomImageDataset(data, labels, transform)\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Compute class weights for imbalanced datasets\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "\n",
        "# Waste Classifier Model\n",
        "class WasteClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(WasteClassifier, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64 * 56 * 56, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, len(class_to_idx))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Custom ResNet Model\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion)\n",
        "            )\n",
        "\n",
        "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18(num_classes):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "\n",
        "class_weights_dict = dict(zip(np.unique(labels), class_weights))\n",
        "def run_faster_cnn(img, model, classes):\n",
        "    img = np.array(Image.open(img))\n",
        "    img = transforms.toTensor()(img)\n",
        "    out = model([img])\n",
        "    scores = out[0]['scores']\n",
        "    boxes = out[0]['boxes']\n",
        "    classes = out[0]['classes']\n",
        "    if len(scores) > 0:\n",
        "        plt.imshow(img)\n",
        "        ax = plt.gca()\n",
        "        for box in boxes.detach().numpy():\n",
        "            xbox_min, ybox_min, xbox_max, ybox_max = box\n",
        "            width = xbox_max - xbox_min\n",
        "            height = ybox_max - ybox_min\n",
        "            rect = Rectangle((xbox_min, ybox_min), width, height, linewidth=2, edgecolour='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "        plt.show()\n",
        "    class_labels = [classes[val.item()-1] for val in classes]\n",
        "    return class_labels\n",
        "\n",
        "def load_model(weights_dict):\n",
        "    # frcnn_args_inference = {'box_score_thresh': 0.75, 'box_detections_per_img': 32}\n",
        "    model = detection.fasterrcnn_resnet50_fpn(weights_dict)\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "faster_cnn_model = load_model(class_weights_dict)\n",
        "faster_cnn_model._modules.keys()\n",
        "# model3 = run_faster_cnn(img, faster_cnn_model, num_classes=len(class_to_idx)).to(device)\n",
        "\n",
        "# YOLO model\n",
        "class YOLO(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(YOLO, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 48, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(48, 32, kernel_size=1)\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 64, kernel_size=1)\n",
        "        self.conv6 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv7 = nn.Conv2d(128, 64, kernel_size=1)\n",
        "        self.conv8 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv9 = nn.Conv2d(128, 64, kernel_size=1)\n",
        "        self.conv10 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv11 = nn.Conv2d(128, 64, kernel_size=1)\n",
        "        self.conv12 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(128, 64, kernel_size=1)\n",
        "        self.conv14 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv15 = nn.Conv2d(128, 128, kernel_size=1)\n",
        "        self.conv16 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv17 = nn.Conv2d(256, 128, kernel_size=1)\n",
        "        self.conv18 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv19 = nn.Conv2d(256, 128, kernel_size=1)\n",
        "        self.conv20 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv21 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv23 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv24 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv25 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv26 = nn.Conv2d(256, 128, kernel_size=1)\n",
        "        self.conv27 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv28 = nn.Conv2d(256, 1024, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(1024, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.maxpool3(x)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = F.relu(self.conv8(x))\n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = F.relu(self.conv10(x))\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        x = F.relu(self.conv13(x))\n",
        "        x = F.relu(self.conv14(x))\n",
        "        x = F.relu(self.conv15(x))\n",
        "        x = F.relu(self.conv16(x))\n",
        "        x = self.maxpool4(x)\n",
        "        x = F.relu(self.conv17(x))\n",
        "        x = F.relu(self.conv18(x))\n",
        "        x = F.relu(self.conv19(x))\n",
        "        x = F.relu(self.conv20(x))\n",
        "        x = F.relu(self.conv21(x))\n",
        "        x = F.relu(self.conv22(x))\n",
        "        x = F.relu(self.conv23(x))\n",
        "        x = F.relu(self.conv24(x))\n",
        "        x = F.relu(self.conv25(x))\n",
        "        x = F.relu(self.conv26(x))\n",
        "        x = F.relu(self.conv27(x))\n",
        "        x = F.relu(self.conv28(x))\n",
        "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Instantiate both models\n",
        "model1 = WasteClassifier(num_classes=len(class_to_idx)).to(device)\n",
        "model2 = resnet18(num_classes=len(class_to_idx)).to(device)\n",
        "\n",
        "\n",
        "# Optimizers and loss functions\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
        "criterion1 = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "criterion2 = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "\n",
        "# Unified training function for both models\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Train both models separately\n",
        "print(\"\\nTraining WasteClassifier...\")\n",
        "train.train_model(model1, optimizer1, criterion1, train_loader, val_loader)\n",
        "\n",
        "print(\"\\nTraining Custom ResNet Model...\")\n",
        "train.train_model(model2, optimizer2, criterion2, train_loader, val_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    total_test = 0\n",
        "    correct_test = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (preds == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    accuracy = correct_test / total_test * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate both models\n",
        "print(\"\\nEvaluating WasteClassifier...\")\n",
        "evaluate_model(model1, test_loader)\n",
        "\n",
        "print(\"\\nEvaluating Custom ResNet Model...\")\n",
        "evaluate_model(model2, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
